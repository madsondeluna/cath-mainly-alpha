{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Ambiente configurado com sucesso!\n",
      "============================================================\n",
      "\n",
      "Python: /Volumes/promethion/cath-mainly-alpha/.venv/bin/python\n",
      "Requests: 2.32.5\n",
      "Pandas: 2.3.3\n",
      "Numpy: 2.3.5\n",
      "Matplotlib: 3.10.7\n",
      "Seaborn: 0.13.2\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Imports principais\n",
    "import sys\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuracoes de visualizacao\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Ambiente configurado com sucesso!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPython: {sys.executable}\")\n",
    "print(f\"Requests: {requests.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "print(f\"Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn: {sns.__version__}\")\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATH MAINLY-ALPHA STRUCTURE DOWNLOADER\n",
      "Ambiente Local - Processamento Paralelo Otimizado\n",
      "============================================================\n",
      "\n",
      "Verificando estrutura de diretorios:\n",
      "  Base: /Volumes/promethion/cath-mainly-alpha - OK\n",
      "  Structures: /Volumes/promethion/cath-mainly-alpha/structures - OK\n",
      "  Logs: /Volumes/promethion/cath-mainly-alpha/logs - OK\n",
      "\n",
      "Diretorio base: /Volumes/promethion/cath-mainly-alpha\n",
      "\n",
      "Baixando lista de dominios CATH...\n",
      "Arquivo CATH salvo: /Volumes/promethion/cath-mainly-alpha/cath-domain-list.txt\n",
      "Processando arquivo CATH...\n",
      "Arquivo CATH salvo: /Volumes/promethion/cath-mainly-alpha/cath-domain-list.txt\n",
      "Processando arquivo CATH...\n",
      "Total de estruturas PDB mainly-alpha: 50996\n",
      "\n",
      "Iniciando download de 50996 estruturas...\n",
      "Workers paralelos: 16\n",
      "Salvando em: /Volumes/promethion/cath-mainly-alpha/structures\n",
      "\n",
      "Total de estruturas PDB mainly-alpha: 50996\n",
      "\n",
      "Iniciando download de 50996 estruturas...\n",
      "Workers paralelos: 16\n",
      "Salvando em: /Volumes/promethion/cath-mainly-alpha/structures\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/promethion/cath-mainly-alpha/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading PDB structures:  22%|██▏       | 11317/50996 [10:03<33:20, 19.84it/s, Success=11316, Exists=0, Error=1]  "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script otimizado para ambiente local: baixar estruturas mainly-alpha do CATH\n",
    "Versao paralela otimizada para macOS\n",
    "\"\"\"\n",
    "\n",
    "# Configuracoes para ambiente local\n",
    "BASE_PATH = \"/Volumes/promethion/cath-mainly-alpha\"\n",
    "CATH_DOMAIN_LIST_URL = \"http://download.cathdb.info/cath/releases/latest-release/cath-classification-data/cath-domain-list.txt\"\n",
    "PDB_DOWNLOAD_URL = \"https://files.rcsb.org/download/{}.pdb\"\n",
    "MAINLY_ALPHA_CLASS = \"1\"  # Class 1 no CATH = Mainly Alpha\n",
    "\n",
    "# Parametros de otimizacao para processamento paralelo\n",
    "import multiprocessing\n",
    "MAX_WORKERS = min(20, multiprocessing.cpu_count() * 2)  # Otimizado para downloads paralelos\n",
    "CHUNK_SIZE = 1024 * 1024  # 1MB para streaming\n",
    "REQUEST_TIMEOUT = 30  # Timeout em segundos\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"\n",
    "    Cria estrutura de diretorios local\n",
    "    \"\"\"\n",
    "    base_path = Path(BASE_PATH)\n",
    "    structures_path = base_path / \"structures\"\n",
    "    logs_path = base_path / \"logs\"\n",
    "\n",
    "    # Cria diretorios\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "    structures_path.mkdir(parents=True, exist_ok=True)\n",
    "    logs_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Verifica criacao\n",
    "    print(\"Verificando estrutura de diretorios:\")\n",
    "    print(f\"  Base: {base_path} - {'OK' if base_path.exists() else 'FALHA'}\")\n",
    "    print(f\"  Structures: {structures_path} - {'OK' if structures_path.exists() else 'FALHA'}\")\n",
    "    print(f\"  Logs: {logs_path} - {'OK' if logs_path.exists() else 'FALHA'}\\n\")\n",
    "\n",
    "    if not (base_path.exists() and structures_path.exists() and logs_path.exists()):\n",
    "        raise RuntimeError(\"Falha ao criar estrutura de diretorios\")\n",
    "\n",
    "    return base_path, structures_path, logs_path\n",
    "\n",
    "def download_cath_domain_list(base_path):\n",
    "    \"\"\"\n",
    "    Baixa o arquivo de lista de dominios CATH\n",
    "    \"\"\"\n",
    "    print(\"Baixando lista de dominios CATH...\")\n",
    "\n",
    "    cath_file = base_path / \"cath-domain-list.txt\"\n",
    "\n",
    "    # Nao baixa novamente se ja existe\n",
    "    if cath_file.exists():\n",
    "        print(f\"Arquivo CATH ja existe: {cath_file}\")\n",
    "        return str(cath_file)\n",
    "\n",
    "    response = requests.get(CATH_DOMAIN_LIST_URL, timeout=60)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(cath_file, 'w') as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "    print(f\"Arquivo CATH salvo: {cath_file}\")\n",
    "    return str(cath_file)\n",
    "\n",
    "def parse_cath_domains(cath_file):\n",
    "    \"\"\"\n",
    "    Parse do arquivo CATH para extrair codigos PDB de estruturas mainly-alpha\n",
    "    \"\"\"\n",
    "    pdb_codes = set()\n",
    "\n",
    "    print(\"Processando arquivo CATH...\")\n",
    "\n",
    "    with open(cath_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "\n",
    "            domain_id = parts[0]\n",
    "            cath_class = parts[1]\n",
    "\n",
    "            if cath_class == MAINLY_ALPHA_CLASS:\n",
    "                pdb_code = domain_id[:4].lower()\n",
    "                pdb_codes.add(pdb_code)\n",
    "\n",
    "    print(f\"Total de estruturas PDB mainly-alpha: {len(pdb_codes)}\")\n",
    "    return pdb_codes\n",
    "\n",
    "def download_single_pdb(pdb_code, output_dir):\n",
    "    \"\"\"\n",
    "    Baixa uma unica estrutura PDB\n",
    "    \"\"\"\n",
    "    output_file = output_dir / f\"{pdb_code}.pdb\"\n",
    "\n",
    "    # Verifica se ja existe\n",
    "    if output_file.exists():\n",
    "        return {\n",
    "            'pdb_code': pdb_code,\n",
    "            'status': 'exists',\n",
    "            'message': 'Arquivo ja existe'\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        url = PDB_DOWNLOAD_URL.format(pdb_code.upper())\n",
    "        response = requests.get(url, timeout=REQUEST_TIMEOUT, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Download com streaming para economizar memoria\n",
    "        with open(output_file, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "        return {\n",
    "            'pdb_code': pdb_code,\n",
    "            'status': 'success',\n",
    "            'message': 'Download concluido'\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        return {\n",
    "            'pdb_code': pdb_code,\n",
    "            'status': 'error',\n",
    "            'message': f'HTTP {e.response.status_code}'\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'pdb_code': pdb_code,\n",
    "            'status': 'error',\n",
    "            'message': str(e)\n",
    "        }\n",
    "\n",
    "def download_structures_parallel(pdb_codes, output_dir, max_workers=MAX_WORKERS):\n",
    "    \"\"\"\n",
    "    Baixa estruturas em paralelo com barra de progresso\n",
    "    \"\"\"\n",
    "    from tqdm.auto import tqdm\n",
    "    \n",
    "    pdb_list = sorted(list(pdb_codes))\n",
    "    total = len(pdb_list)\n",
    "\n",
    "    results = {\n",
    "        'total': total,\n",
    "        'success': 0,\n",
    "        'exists': 0,\n",
    "        'error': 0,\n",
    "        'failed_codes': []\n",
    "    }\n",
    "\n",
    "    print(f\"\\nIniciando download de {total} estruturas...\")\n",
    "    print(f\"Workers paralelos: {max_workers}\")\n",
    "    print(f\"Salvando em: {output_dir}\\n\")\n",
    "\n",
    "    # Download paralelo com barra de progresso\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(download_single_pdb, pdb_code, output_dir): pdb_code\n",
    "            for pdb_code in pdb_list\n",
    "        }\n",
    "\n",
    "        # Barra de progresso\n",
    "        with tqdm(total=total, desc=\"Downloading PDB structures\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "\n",
    "                if result['status'] == 'success':\n",
    "                    results['success'] += 1\n",
    "                elif result['status'] == 'exists':\n",
    "                    results['exists'] += 1\n",
    "                elif result['status'] == 'error':\n",
    "                    results['error'] += 1\n",
    "                    results['failed_codes'].append(result['pdb_code'])\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                    'Success': results['success'],\n",
    "                    'Exists': results['exists'],\n",
    "                    'Error': results['error']\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_download_results(base_path, pdb_codes, results):\n",
    "    \"\"\"\n",
    "    Salva listas de codigos PDB e resultados\n",
    "    \"\"\"\n",
    "    logs_path = base_path / \"logs\"\n",
    "    logs_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not logs_path.exists():\n",
    "        raise RuntimeError(f\"Falha ao criar diretorio de logs: {logs_path}\")\n",
    "\n",
    "    # Lista completa de codigos\n",
    "    codes_file = base_path / \"mainly_alpha_pdb_codes.txt\"\n",
    "    try:\n",
    "        with open(codes_file, 'w') as f:\n",
    "            for code in sorted(pdb_codes):\n",
    "                f.write(f\"{code}\\n\")\n",
    "        print(f\"Lista de codigos PDB salva em: {codes_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar lista de codigos: {e}\")\n",
    "\n",
    "    # Codigos que falharam\n",
    "    if results['failed_codes']:\n",
    "        failed_file = logs_path / \"failed_downloads.txt\"\n",
    "        try:\n",
    "            with open(failed_file, 'w') as f:\n",
    "                for code in sorted(results['failed_codes']):\n",
    "                    f.write(f\"{code}\\n\")\n",
    "            print(f\"Codigos com falha salvos em: {failed_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao salvar lista de falhas: {e}\")\n",
    "\n",
    "    # Relatorio detalhado\n",
    "    report_file = logs_path / \"download_report.txt\"\n",
    "    try:\n",
    "        with open(report_file, 'w') as f:\n",
    "            f.write(\"=\"*60 + \"\\n\")\n",
    "            f.write(\"RELATORIO DE DOWNLOAD - CATH MAINLY-ALPHA\\n\")\n",
    "            f.write(\"=\"*60 + \"\\n\\n\")\n",
    "            f.write(f\"Total de estruturas: {results['total']}\\n\")\n",
    "            f.write(f\"Downloads bem-sucedidos: {results['success']}\\n\")\n",
    "            f.write(f\"Ja existentes: {results['exists']}\\n\")\n",
    "            f.write(f\"Falhas: {results['error']}\\n\")\n",
    "            f.write(f\"Taxa de sucesso: {(results['success'] + results['exists'])/results['total']*100:.1f}%\\n\")\n",
    "            f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "        print(f\"Relatorio salvo em: {report_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar relatorio: {e}\")\n",
    "\n",
    "def print_download_report(results, structures_path):\n",
    "    \"\"\"\n",
    "    Exibe relatorio final\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RELATORIO FINAL DE DOWNLOAD\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total de estruturas: {results['total']}\")\n",
    "    print(f\"Downloads bem-sucedidos: {results['success']}\")\n",
    "    print(f\"Ja existentes (nao baixados): {results['exists']}\")\n",
    "    print(f\"Falhas: {results['error']}\")\n",
    "    print(f\"Taxa de sucesso: {(results['success'] + results['exists'])/results['total']*100:.1f}%\")\n",
    "    print(f\"\\nEstruturas salvas em: {structures_path}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# ========== EXECUCAO ==========\n",
    "print(\"=\"*60)\n",
    "print(\"CATH MAINLY-ALPHA STRUCTURE DOWNLOADER\")\n",
    "print(\"Ambiente Local - Processamento Paralelo Otimizado\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    # 1. Setup de diretorios\n",
    "    base_path, structures_path, logs_path = setup_directories()\n",
    "    print(f\"Diretorio base: {base_path}\\n\")\n",
    "\n",
    "    # 2. Baixa arquivo CATH\n",
    "    cath_file = download_cath_domain_list(base_path)\n",
    "\n",
    "    # 3. Extrai codigos PDB\n",
    "    pdb_codes = parse_cath_domains(cath_file)\n",
    "\n",
    "    # 4. Baixa estruturas em paralelo\n",
    "    results = download_structures_parallel(pdb_codes, structures_path)\n",
    "\n",
    "    # 5. Salva resultados\n",
    "    save_download_results(base_path, pdb_codes, results)\n",
    "\n",
    "    # 6. Relatorio final\n",
    "    print_download_report(results, structures_path)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro critico na execucao: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424,
     "referenced_widgets": [
      "2641f2753d1a4e9da3f9bbab6f7f2685",
      "92d2a2552fb741519a0f461ba756acf5",
      "297baed59b124f63ad88025b11894011",
      "8a202abdac1049a08387e2b20c85aab8",
      "42f9116bd30c48c996a697ec3163f940",
      "cc52aee002574e5b8914ec6666d173e2",
      "7a1596b23b184c2e89ca9a36039dcca4",
      "0d876f034b7c4c7fb5763f7eede217c5",
      "1854649ee670442791d36ace0e288eb1",
      "96d57df4024249398fb57774783dc437",
      "2a8ecdeae85c4edfba1d693a774fa5d7"
     ]
    },
    "id": "OQjk1PQWL642",
    "outputId": "719679ae-ead6-4505-ba62-44371332d174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LIMPEZA DE ESTRUTURAS CATH MAINLY-ALPHA\n",
      "Ambiente Local - Processamento Paralelo\n",
      "============================================================\n",
      "\n",
      "ERRO: Pasta de estruturas não encontrada em /Users/madsonluna/Documents/cath/structures\n",
      "Execute primeiro o script de download!\n",
      "\n",
      "⚠️  Execute primeiro a célula de download!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script para limpeza de estruturas PDB em ambiente local\n",
    "Remove heteroátomos, água, íons e mantém apenas cadeia A\n",
    "Versão com processamento paralelo otimizado\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "# Dependências necessárias (instalar se não tiver):\n",
    "# pip install biopython tqdm\n",
    "\n",
    "from Bio import PDB\n",
    "from Bio.PDB import PDBIO, Select\n",
    "\n",
    "# Configurações para ambiente local\n",
    "BASE_PATH = \"/Volumes/promethion/cath-mainly-alpha\"\n",
    "MAX_WORKERS = max(1, multiprocessing.cpu_count() - 1)  # Usa CPU-1 para deixar sistema responsivo\n",
    "\n",
    "# Aminoácidos padrão\n",
    "STANDARD_AMINO_ACIDS = {\n",
    "    'ALA', 'ARG', 'ASN', 'ASP', 'CYS',\n",
    "    'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
    "    'LEU', 'LYS', 'MET', 'PHE', 'PRO',\n",
    "    'SER', 'THR', 'TRP', 'TYR', 'VAL'\n",
    "}\n",
    "\n",
    "class ChainAOnlySelect(Select):\n",
    "    \"\"\"\n",
    "    Seleciona apenas cadeia A e remove heteroátomos\n",
    "    \"\"\"\n",
    "    def accept_model(self, model):\n",
    "        return model.id == 0\n",
    "\n",
    "    def accept_chain(self, chain):\n",
    "        return chain.id == 'A'\n",
    "\n",
    "    def accept_residue(self, residue):\n",
    "        hetfield = residue.id[0]\n",
    "        if hetfield != ' ':\n",
    "            return False\n",
    "        return residue.resname.strip() in STANDARD_AMINO_ACIDS\n",
    "\n",
    "    def accept_atom(self, atom):\n",
    "        return True\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"\n",
    "    Verifica e cria diretórios necessários\n",
    "    \"\"\"\n",
    "    base_path = Path(BASE_PATH)\n",
    "\n",
    "    # Procura estruturas baixadas\n",
    "    structures_raw = base_path / \"structures\"\n",
    "    if not structures_raw.exists():\n",
    "        print(f\"ERRO: Pasta de estruturas não encontrada em {structures_raw}\")\n",
    "        print(\"Execute primeiro o script de download!\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Cria pastas de saída\n",
    "    clean_path = base_path / \"structures_clean\"\n",
    "    logs_path = base_path / \"logs\"\n",
    "\n",
    "    clean_path.mkdir(exist_ok=True)\n",
    "    logs_path.mkdir(exist_ok=True)\n",
    "\n",
    "    return base_path, structures_raw, clean_path, logs_path\n",
    "\n",
    "def clean_single_structure(input_file: Path, output_file: Path) -> Dict:\n",
    "    \"\"\"\n",
    "    Limpa uma estrutura PDB individual\n",
    "    \"\"\"\n",
    "    pdb_code = input_file.stem\n",
    "\n",
    "    # Se já foi processada, pula\n",
    "    if output_file.exists():\n",
    "        return {\n",
    "            'pdb_code': pdb_code,\n",
    "            'status': 'exists',\n",
    "            'residues': 0\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        parser = PDB.PDBParser(QUIET=True)\n",
    "        structure = parser.get_structure(pdb_code, str(input_file))\n",
    "\n",
    "        # Verifica cadeia A\n",
    "        has_chain_a = any('A' in [c.id for c in m] for m in structure)\n",
    "\n",
    "        if not has_chain_a:\n",
    "            return {\n",
    "                'pdb_code': pdb_code,\n",
    "                'status': 'no_chain_a',\n",
    "                'residues': 0\n",
    "            }\n",
    "\n",
    "        # Salva apenas cadeia A limpa\n",
    "        io = PDBIO()\n",
    "        io.set_structure(structure)\n",
    "        io.save(str(output_file), ChainAOnlySelect())\n",
    "\n",
    "        # Conta resíduos\n",
    "        clean_structure = parser.get_structure(pdb_code, str(output_file))\n",
    "        residue_count = sum(\n",
    "            len([r for r in c if r.id[0] == ' '])\n",
    "            for m in clean_structure for c in m\n",
    "        )\n",
    "\n",
    "        if residue_count == 0:\n",
    "            output_file.unlink()\n",
    "            return {\n",
    "                'pdb_code': pdb_code,\n",
    "                'status': 'empty',\n",
    "                'residues': 0\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            'pdb_code': pdb_code,\n",
    "            'status': 'success',\n",
    "            'residues': residue_count\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'pdb_code': pdb_code,\n",
    "            'status': 'error',\n",
    "            'residues': 0,\n",
    "            'message': str(e)\n",
    "        }\n",
    "\n",
    "def clean_all_structures(raw_dir: Path, clean_dir: Path) -> Dict:\n",
    "    \"\"\"\n",
    "    Processa todas as estruturas em paralelo usando múltiplos processos\n",
    "    \"\"\"\n",
    "    pdb_files = list(raw_dir.glob(\"*.pdb\"))\n",
    "\n",
    "    if not pdb_files:\n",
    "        print(f\"\\nERRO: Nenhum arquivo .pdb encontrado em {raw_dir}\")\n",
    "        return None\n",
    "\n",
    "    total = len(pdb_files)\n",
    "    existing_clean = len(list(clean_dir.glob(\"*.pdb\")))\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LIMPEZA DE ESTRUTURAS PDB - PROCESSAMENTO PARALELO\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nTotal de estruturas brutas: {total:,}\")\n",
    "    print(f\"Já processadas: {existing_clean:,}\")\n",
    "    print(f\"Restantes: {total - existing_clean:,}\")\n",
    "    print(f\"Workers (CPUs): {MAX_WORKERS}\")\n",
    "\n",
    "    if existing_clean == total:\n",
    "        print(\"\\n✓ Todas as estruturas já foram limpas!\")\n",
    "        return {\n",
    "            'total': total,\n",
    "            'success': existing_clean,\n",
    "            'exists': existing_clean,\n",
    "            'no_chain_a': 0,\n",
    "            'empty': 0,\n",
    "            'error': 0,\n",
    "            'total_residues': 0,\n",
    "            'no_chain_a_codes': [],\n",
    "            'error_codes': []\n",
    "        }\n",
    "\n",
    "    print(f\"\\nIniciando limpeza paralela...\\n\")\n",
    "\n",
    "    results = {\n",
    "        'total': total,\n",
    "        'success': 0,\n",
    "        'exists': 0,\n",
    "        'no_chain_a': 0,\n",
    "        'empty': 0,\n",
    "        'error': 0,\n",
    "        'total_residues': 0,\n",
    "        'no_chain_a_codes': [],\n",
    "        'error_codes': []\n",
    "    }\n",
    "\n",
    "    # Processamento paralelo com ThreadPoolExecutor (I/O bound)\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = {\n",
    "            executor.submit(clean_single_structure, pdb_file, clean_dir / pdb_file.name): pdb_file\n",
    "            for pdb_file in pdb_files\n",
    "        }\n",
    "\n",
    "        with tqdm(total=total, desc=\"Cleaning structures\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "\n",
    "                if result['status'] == 'success':\n",
    "                    results['success'] += 1\n",
    "                    results['total_residues'] += result['residues']\n",
    "                elif result['status'] == 'exists':\n",
    "                    results['exists'] += 1\n",
    "                elif result['status'] == 'no_chain_a':\n",
    "                    results['no_chain_a'] += 1\n",
    "                    results['no_chain_a_codes'].append(result['pdb_code'])\n",
    "                elif result['status'] == 'empty':\n",
    "                    results['empty'] += 1\n",
    "                elif result['status'] == 'error':\n",
    "                    results['error'] += 1\n",
    "                    results['error_codes'].append(result['pdb_code'])\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                    'OK': results['success'],\n",
    "                    'Exist': results['exists'],\n",
    "                    'NoChainA': results['no_chain_a'],\n",
    "                    'Error': results['error']\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_cleaning_results(logs_path: Path, clean_results: Dict):\n",
    "    \"\"\"\n",
    "    Salva resultados da limpeza\n",
    "    \"\"\"\n",
    "    # Log de estruturas sem cadeia A\n",
    "    if clean_results['no_chain_a_codes']:\n",
    "        no_chain_file = logs_path / \"no_chain_a.txt\"\n",
    "        with open(no_chain_file, 'w') as f:\n",
    "            for code in sorted(clean_results['no_chain_a_codes']):\n",
    "                f.write(f\"{code}\\n\")\n",
    "        print(f\"\\nEstruturas sem cadeia A: {no_chain_file}\")\n",
    "\n",
    "    # Log de erros\n",
    "    if clean_results['error_codes']:\n",
    "        error_file = logs_path / \"cleaning_errors.txt\"\n",
    "        with open(error_file, 'w') as f:\n",
    "            for code in sorted(clean_results['error_codes']):\n",
    "                f.write(f\"{code}\\n\")\n",
    "        print(f\"Erros de processamento: {error_file}\")\n",
    "\n",
    "    # Relatório de limpeza\n",
    "    report_file = logs_path / \"cleaning_report.txt\"\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"RELATÓRIO DE LIMPEZA - CATH MAINLY-ALPHA\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Total de estruturas: {clean_results['total']:,}\\n\")\n",
    "        f.write(f\"Limpas com sucesso: {clean_results['success']:,}\\n\")\n",
    "        f.write(f\"Já existiam: {clean_results['exists']:,}\\n\")\n",
    "        f.write(f\"Sem cadeia A: {clean_results['no_chain_a']:,}\\n\")\n",
    "        f.write(f\"Vazias após limpeza: {clean_results['empty']:,}\\n\")\n",
    "        f.write(f\"Erros: {clean_results['error']:,}\\n\")\n",
    "        f.write(f\"Total de resíduos: {clean_results['total_residues']:,}\\n\")\n",
    "\n",
    "        if clean_results['success'] > 0:\n",
    "            avg = clean_results['total_residues'] / clean_results['success']\n",
    "            f.write(f\"Média de resíduos/estrutura: {avg:.1f}\\n\")\n",
    "\n",
    "        f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "    print(f\"Relatório de limpeza: {report_file}\")\n",
    "\n",
    "def print_cleaning_summary(clean_results: Dict, raw_dir: Path, clean_dir: Path):\n",
    "    \"\"\"\n",
    "    Exibe resumo da limpeza\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"RESUMO DA LIMPEZA\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nEstrutura de diretórios:\")\n",
    "    print(f\"  Raw (originais):  {raw_dir}\")\n",
    "    print(f\"  Clean (limpas):   {clean_dir}\")\n",
    "\n",
    "    print(f\"\\nResultados da limpeza:\")\n",
    "    print(f\"  Total processadas:     {clean_results['total']:,}\")\n",
    "    print(f\"  Sucesso:               {clean_results['success']:,}\")\n",
    "    print(f\"  Já existiam:           {clean_results['exists']:,}\")\n",
    "    print(f\"  Sem cadeia A:          {clean_results['no_chain_a']:,}\")\n",
    "    print(f\"  Vazias:                {clean_results['empty']:,}\")\n",
    "    print(f\"  Erros:                 {clean_results['error']:,}\")\n",
    "\n",
    "    total_ok = clean_results['success'] + clean_results['exists']\n",
    "    print(f\"\\nEstruturas limpas disponíveis: {total_ok:,}\")\n",
    "\n",
    "    if clean_results['total_residues'] > 0:\n",
    "        print(f\"Total de resíduos: {clean_results['total_residues']:,}\")\n",
    "\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# ========== EXECUÇÃO ==========\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"LIMPEZA DE ESTRUTURAS CATH MAINLY-ALPHA\")\n",
    "print(\"Ambiente Local - Processamento Paralelo\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "try:\n",
    "    # 1. Setup de diretórios\n",
    "    paths = setup_directories()\n",
    "    if paths[0] is None:\n",
    "        print(\"\\nExecute primeiro a célula de download!\")\n",
    "    else:\n",
    "        base_path, raw_dir, clean_dir, logs_path = paths\n",
    "\n",
    "        print(f\"Diretório base: {base_path}\")\n",
    "        print(f\"Estruturas raw: {raw_dir}\")\n",
    "        print(f\"Estruturas clean: {clean_dir}\")\n",
    "\n",
    "        # 2. Limpa estruturas\n",
    "        clean_results = clean_all_structures(raw_dir, clean_dir)\n",
    "\n",
    "        if clean_results is not None:\n",
    "            # 3. Salva resultados\n",
    "            save_cleaning_results(logs_path, clean_results)\n",
    "\n",
    "            # 4. Resumo\n",
    "            print_cleaning_summary(clean_results, raw_dir, clean_dir)\n",
    "\n",
    "            print(f\"\\n✓ Limpeza concluída! Execute a próxima célula para análise de frequência.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro crítico na execução: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Análise de frequência de aminoácidos nas estruturas limpas\n",
    "Processamento paralelo otimizado\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from Bio import PDB\n",
    "\n",
    "# Configurações\n",
    "BASE_PATH = \"/Volumes/promethion/cath-mainly-alpha\"\n",
    "\n",
    "# Aminoácidos padrão\n",
    "STANDARD_AMINO_ACIDS = {\n",
    "    'ALA', 'ARG', 'ASN', 'ASP', 'CYS',\n",
    "    'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
    "    'LEU', 'LYS', 'MET', 'PHE', 'PRO',\n",
    "    'SER', 'THR', 'TRP', 'TYR', 'VAL'\n",
    "}\n",
    "\n",
    "def analyze_amino_acid_frequency(clean_dir: Path):\n",
    "    \"\"\"\n",
    "    Analisa frequência de aminoácidos em paralelo\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ANÁLISE DE FREQUÊNCIA DE AMINOÁCIDOS\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    pdb_files = list(clean_dir.glob(\"*.pdb\"))\n",
    "\n",
    "    if not pdb_files:\n",
    "        print(\"ERRO: Nenhuma estrutura limpa encontrada!\")\n",
    "        print(f\"Execute primeiro a célula de limpeza!\")\n",
    "        return None, None\n",
    "\n",
    "    print(f\"Analisando {len(pdb_files):,} estruturas...\\n\")\n",
    "\n",
    "    global_counter = Counter()\n",
    "    per_structure = {}\n",
    "    parser = PDB.PDBParser(QUIET=True)\n",
    "\n",
    "    with tqdm(total=len(pdb_files), desc=\"Analyzing\") as pbar:\n",
    "        for pdb_file in pdb_files:\n",
    "            try:\n",
    "                structure = parser.get_structure(pdb_file.stem, str(pdb_file))\n",
    "                local_counter = Counter()\n",
    "\n",
    "                for model in structure:\n",
    "                    for chain in model:\n",
    "                        for residue in chain:\n",
    "                            if residue.id[0] == ' ':\n",
    "                                resname = residue.resname.strip()\n",
    "                                if resname in STANDARD_AMINO_ACIDS:\n",
    "                                    global_counter[resname] += 1\n",
    "                                    local_counter[resname] += 1\n",
    "\n",
    "                per_structure[pdb_file.stem] = dict(local_counter)\n",
    "            except Exception:\n",
    "                pass\n",
    "            pbar.update(1)\n",
    "\n",
    "    return global_counter, per_structure\n",
    "\n",
    "def save_frequency_results(analysis_path: Path, global_counter: Counter, per_structure: dict):\n",
    "    \"\"\"\n",
    "    Salva resultados de frequência\n",
    "    \"\"\"\n",
    "    # Frequências globais\n",
    "    total_residues = sum(global_counter.values())\n",
    "\n",
    "    freq_file = analysis_path / \"amino_acid_frequencies_global.txt\"\n",
    "    with open(freq_file, 'w') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"FREQUÊNCIA GLOBAL DE AMINOÁCIDOS\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Total de resíduos: {total_residues:,}\\n\")\n",
    "        f.write(f\"Total de estruturas: {len(per_structure):,}\\n\\n\")\n",
    "        f.write(f\"{'AA':<5} {'Contagem':<12} {'Frequência (%)':<15}\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "\n",
    "        for aa, count in global_counter.most_common():\n",
    "            freq = (count / total_residues) * 100\n",
    "            f.write(f\"{aa:<5} {count:<12,} {freq:>14.2f}%\\n\")\n",
    "\n",
    "    print(f\"\\nFrequências globais: {freq_file}\")\n",
    "\n",
    "    # CSV por estrutura\n",
    "    csv_file = analysis_path / \"amino_acid_frequencies_per_structure.csv\"\n",
    "    with open(csv_file, 'w') as f:\n",
    "        all_aa = sorted(STANDARD_AMINO_ACIDS)\n",
    "        f.write(\"PDB_Code,\" + \",\".join(all_aa) + \",Total\\n\")\n",
    "\n",
    "        for pdb_code in sorted(per_structure.keys()):\n",
    "            counts = per_structure[pdb_code]\n",
    "            row = [pdb_code] + [str(counts.get(aa, 0)) for aa in all_aa]\n",
    "            row.append(str(sum(counts.values())))\n",
    "            f.write(\",\".join(row) + \"\\n\")\n",
    "\n",
    "    print(f\"Frequências por estrutura: {csv_file}\")\n",
    "\n",
    "def print_frequency_summary(global_counter: Counter, per_structure: dict):\n",
    "    \"\"\"\n",
    "    Exibe resumo das análises\n",
    "    \"\"\"\n",
    "    total_residues = sum(global_counter.values())\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"RESUMO DA ANÁLISE DE FREQUÊNCIA\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nTotal de estruturas analisadas: {len(per_structure):,}\")\n",
    "    print(f\"Total de resíduos: {total_residues:,}\")\n",
    "\n",
    "    print(f\"\\nTop 5 aminoácidos mais frequentes:\")\n",
    "    for aa, count in global_counter.most_common(5):\n",
    "        freq = (count / total_residues) * 100\n",
    "        print(f\"  {aa}: {count:,} ({freq:.2f}%)\")\n",
    "\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# ========== EXECUÇÃO ==========\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ANÁLISE DE FREQUÊNCIA DE AMINOÁCIDOS\")\n",
    "print(\"Ambiente Local\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "try:\n",
    "    base_path = Path(BASE_PATH)\n",
    "    clean_dir = base_path / \"structures_clean\"\n",
    "    analysis_path = base_path / \"analysis\"\n",
    "\n",
    "    # Cria pasta de análise se não existir\n",
    "    analysis_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # Verifica se há estruturas limpas\n",
    "    if not clean_dir.exists():\n",
    "        print(f\"\\nERRO: Pasta de estruturas limpas não encontrada!\")\n",
    "        print(f\"Execute primeiro a célula de limpeza!\")\n",
    "    else:\n",
    "        # Analisa frequências\n",
    "        global_counter, per_structure = analyze_amino_acid_frequency(clean_dir)\n",
    "\n",
    "        if global_counter is not None and per_structure is not None:\n",
    "            # Salva resultados\n",
    "            save_frequency_results(analysis_path, global_counter, per_structure)\n",
    "\n",
    "            # Resumo\n",
    "            print_frequency_summary(global_counter, per_structure)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro crítico na execução: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9036fc7677104d7c836ebdf9a4bc2db7",
      "724cf11fba894348b48d1185401726a8",
      "45b92ad879564fd79ca09b2941f5586c",
      "b3d7f88fa00c433e8f7e31f81b099100",
      "ec7ce0b2be2c4c71bdfd0e99b213ac37",
      "d620d548266542508af9faef614c9e87",
      "5e02ca279b324dea9e3f4d22d41cf9f8",
      "c1f4f66b3f614e94b98c73abc81ffdcc",
      "e0a95389ac504fe38d51bcf762e1c602",
      "ed02965954474837b16945d23df5bdd8",
      "40411b06d28342339692ecddab06b64d",
      "419c7c9a4649464c80f32129dea17446",
      "bbe9253cf1c24002bd57b8e724ac15ce",
      "4632adc7b0f8403a84f67bd9d12f33cb",
      "0228f822aa624ac5987ecbd3bbe6cbf7",
      "293a22c8138243b78e986c8d1fe355a0",
      "0ee5fb2790ff4d78baa5ad19bdffad9a",
      "35a27a27a4ec41e0963290252f54a74c",
      "d5535266ba4b42e89fe03b3dedf4b406",
      "0686afe9d4c741deb71ca3e6e401fbb3",
      "d1a4dd7776f748e4b348b0ed9928ce75",
      "48dc0ee1b606403b8d95eef4d42f7415"
     ]
    },
    "id": "GQFw5R80MWzc",
    "outputId": "216306ff-0c4f-4d52-f03e-119bb062860f"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Análises avançadas de composição de hélices alpha\n",
    "Ambiente local com processamento paralelo\n",
    "\"\"\"\n",
    "\n",
    "from Bio import PDB\n",
    "from Bio.PDB import DSSP, PPBuilder\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# Configurações para ambiente local\n",
    "BASE_PATH = \"/Volumes/promethion/cath-mainly-alpha\"\n",
    "CLEAN_STRUCTURES_PATH = f\"{BASE_PATH}/structures_clean\"\n",
    "MAX_WORKERS = max(1, multiprocessing.cpu_count() - 1)\n",
    "\n",
    "# Aminoácidos agrupados por propriedades\n",
    "AA_PROPERTIES = {\n",
    "    'Hidrofóbico': ['ALA', 'VAL', 'ILE', 'LEU', 'MET', 'PHE', 'TRP', 'PRO'],\n",
    "    'Polar': ['SER', 'THR', 'CYS', 'TYR', 'ASN', 'GLN'],\n",
    "    'Carregado positivo': ['LYS', 'ARG', 'HIS'],\n",
    "    'Carregado negativo': ['ASP', 'GLU'],\n",
    "    'Especial': ['GLY', 'PRO']\n",
    "}\n",
    "\n",
    "# Propensão de aminoácidos para hélices (escala de Chou-Fasman)\n",
    "HELIX_PROPENSITY = {\n",
    "    'ALA': 1.42, 'GLU': 1.51, 'LEU': 1.21, 'MET': 1.45,\n",
    "    'GLN': 1.11, 'LYS': 1.16, 'ARG': 0.98, 'HIS': 1.00,\n",
    "    'VAL': 1.06, 'ILE': 1.08, 'TYR': 0.69, 'PHE': 1.13,\n",
    "    'TRP': 1.08, 'THR': 0.83, 'SER': 0.77, 'CYS': 0.70,\n",
    "    'ASP': 1.01, 'ASN': 0.67, 'GLY': 0.57, 'PRO': 0.57\n",
    "}\n",
    "\n",
    "STANDARD_AMINO_ACIDS = {\n",
    "    'ALA', 'ARG', 'ASN', 'ASP', 'CYS',\n",
    "    'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
    "    'LEU', 'LYS', 'MET', 'PHE', 'PRO',\n",
    "    'SER', 'THR', 'TRP', 'TYR', 'VAL'\n",
    "}\n",
    "\n",
    "def install_dssp():\n",
    "    \"\"\"\n",
    "    Instala DSSP no macOS usando Homebrew\n",
    "    \"\"\"\n",
    "    print(\"\\nVerificando instalação do DSSP...\")\n",
    "    \n",
    "    try:\n",
    "        # Verifica se DSSP já está instalado\n",
    "        result = subprocess.run(['which', 'mkdssp'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"✓ DSSP já instalado em: {result.stdout.strip()}\")\n",
    "            return True\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    print(\"DSSP não encontrado. Instalando via Homebrew...\")\n",
    "    print(\"Execute no terminal: brew install brewsci/bio/dssp\")\n",
    "    print(\"\\nOu instale manualmente de: https://swift.cmbi.umcn.nl/gv/dssp/\")\n",
    "    return False\n",
    "\n",
    "def analyze_single_structure_dssp(pdb_file: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Analisa uma estrutura individual com DSSP\n",
    "    \"\"\"\n",
    "    pdb_code = pdb_file.stem\n",
    "    parser = PDB.PDBParser(QUIET=True)\n",
    "    \n",
    "    try:\n",
    "        structure = parser.get_structure(pdb_code, str(pdb_file))\n",
    "        model = structure[0]\n",
    "        \n",
    "        # DSSP analysis\n",
    "        dssp = DSSP(model, str(pdb_file), dssp='mkdssp')\n",
    "        \n",
    "        helix_residues = Counter()\n",
    "        all_residues = Counter()\n",
    "        helix_positions = defaultdict(lambda: defaultdict(int))\n",
    "        helix_lengths = []\n",
    "        \n",
    "        # Processa estrutura secundária\n",
    "        ss_sequence = []\n",
    "        aa_sequence = []\n",
    "        \n",
    "        for key in dssp.property_keys:\n",
    "            residue = dssp[key]\n",
    "            aa = residue[1]\n",
    "            ss = residue[2]\n",
    "            \n",
    "            ss_sequence.append(ss)\n",
    "            aa_sequence.append(aa)\n",
    "            all_residues[aa] += 1\n",
    "        \n",
    "        # Identifica hélices\n",
    "        current_helix = []\n",
    "        \n",
    "        for i, (ss, aa) in enumerate(zip(ss_sequence, aa_sequence)):\n",
    "            if ss in ['H', 'G', 'I']:\n",
    "                helix_residues[aa] += 1\n",
    "                current_helix.append(aa)\n",
    "            else:\n",
    "                if len(current_helix) >= 4:\n",
    "                    helix_lengths.append(len(current_helix))\n",
    "                    \n",
    "                    for j, res in enumerate(current_helix):\n",
    "                        if j == 0:\n",
    "                            helix_positions['N-terminal'][res] += 1\n",
    "                        elif j == len(current_helix) - 1:\n",
    "                            helix_positions['C-terminal'][res] += 1\n",
    "                        else:\n",
    "                            helix_positions['Middle'][res] += 1\n",
    "                \n",
    "                current_helix = []\n",
    "        \n",
    "        # Última hélice\n",
    "        if len(current_helix) >= 4:\n",
    "            helix_lengths.append(len(current_helix))\n",
    "            for j, res in enumerate(current_helix):\n",
    "                if j == 0:\n",
    "                    helix_positions['N-terminal'][res] += 1\n",
    "                elif j == len(current_helix) - 1:\n",
    "                    helix_positions['C-terminal'][res] += 1\n",
    "                else:\n",
    "                    helix_positions['Middle'][res] += 1\n",
    "        \n",
    "        return {\n",
    "            'pdb_code': pdb_code,\n",
    "            'status': 'success',\n",
    "            'helix_residues': dict(helix_residues),\n",
    "            'all_residues': dict(all_residues),\n",
    "            'helix_positions': dict(helix_positions),\n",
    "            'helix_lengths': helix_lengths\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'pdb_code': pdb_code,\n",
    "            'status': 'error',\n",
    "            'message': str(e)\n",
    "        }\n",
    "\n",
    "def analyze_secondary_structure_with_dssp(clean_dir: Path, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Analisa estrutura secundária usando DSSP com processamento paralelo\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalisando estrutura secundária com DSSP...\")\n",
    "    \n",
    "    if not install_dssp():\n",
    "        print(\"\\n⚠️  DSSP não instalado. Por favor, instale o DSSP para continuar.\")\n",
    "        return None\n",
    "    \n",
    "    pdb_files = list(clean_dir.glob(\"*.pdb\"))\n",
    "    \n",
    "    # Contadores globais\n",
    "    global_helix_residues = Counter()\n",
    "    global_all_residues = Counter()\n",
    "    global_helix_positions = defaultdict(lambda: defaultdict(int))\n",
    "    global_helix_lengths = []\n",
    "    \n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    print(f\"Processando {len(pdb_files):,} estruturas com {MAX_WORKERS} workers...\\n\")\n",
    "    \n",
    "    with tqdm(total=len(pdb_files), desc=\"DSSP Analysis\") as pbar:\n",
    "        for pdb_file in pdb_files:\n",
    "            result = analyze_single_structure_dssp(pdb_file)\n",
    "            \n",
    "            if result['status'] == 'success':\n",
    "                successful += 1\n",
    "                \n",
    "                # Agrega resultados\n",
    "                for aa, count in result['helix_residues'].items():\n",
    "                    global_helix_residues[aa] += count\n",
    "                \n",
    "                for aa, count in result['all_residues'].items():\n",
    "                    global_all_residues[aa] += count\n",
    "                \n",
    "                for pos_type, pos_data in result['helix_positions'].items():\n",
    "                    for aa, count in pos_data.items():\n",
    "                        global_helix_positions[pos_type][aa] += count\n",
    "                \n",
    "                global_helix_lengths.extend(result['helix_lengths'])\n",
    "            else:\n",
    "                failed += 1\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(f\"\\nDSSP concluído: {successful} sucessos, {failed} falhas\")\n",
    "    \n",
    "    return {\n",
    "        'helix_residues': global_helix_residues,\n",
    "        'all_residues': global_all_residues,\n",
    "        'helix_positions': dict(global_helix_positions),\n",
    "        'helix_lengths': global_helix_lengths\n",
    "    }\n",
    "\n",
    "def calculate_helix_propensities(helix_residues: Counter, all_residues: Counter) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calcula propensões observadas vs esperadas para hélices\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    total_helix = sum(helix_residues.values())\n",
    "    total_all = sum(all_residues.values())\n",
    "    \n",
    "    for aa in sorted(STANDARD_AMINO_ACIDS):\n",
    "        helix_count = helix_residues.get(aa, 0)\n",
    "        total_count = all_residues.get(aa, 0)\n",
    "        \n",
    "        if total_count > 0:\n",
    "            freq_helix = (helix_count / total_helix) * 100\n",
    "            freq_expected = (total_count / total_all) * 100\n",
    "            propensity_observed = freq_helix / freq_expected if freq_expected > 0 else 0\n",
    "            propensity_theoretical = HELIX_PROPENSITY.get(aa, 1.0)\n",
    "            \n",
    "            data.append({\n",
    "                'AA': aa,\n",
    "                'Count_Helix': helix_count,\n",
    "                'Count_Total': total_count,\n",
    "                'Freq_Helix': freq_helix,\n",
    "                'Freq_Total': freq_expected,\n",
    "                'Propensity_Observed': propensity_observed,\n",
    "                'Propensity_Theoretical': propensity_theoretical\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def analyze_helix_positions(helix_positions: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analisa preferências de aminoácidos em diferentes posições da hélice\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    positions = ['N-terminal', 'Middle', 'C-terminal']\n",
    "    \n",
    "    for pos in positions:\n",
    "        pos_counts = helix_positions.get(pos, {})\n",
    "        total = sum(pos_counts.values())\n",
    "        \n",
    "        for aa in sorted(STANDARD_AMINO_ACIDS):\n",
    "            count = pos_counts.get(aa, 0)\n",
    "            freq = (count / total * 100) if total > 0 else 0\n",
    "            \n",
    "            data.append({\n",
    "                'Position': pos,\n",
    "                'AA': aa,\n",
    "                'Count': count,\n",
    "                'Frequency': freq\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def analyze_hydrophobic_patterns(clean_dir: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Analisa padrões de hidrofobicidade em hélices\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalisando padrões de hidrofobicidade...\")\n",
    "    \n",
    "    hydrophobic = set(['ALA', 'VAL', 'ILE', 'LEU', 'MET', 'PHE', 'TRP'])\n",
    "    \n",
    "    pdb_files = list(clean_dir.glob(\"*.pdb\"))\n",
    "    parser = PDB.PDBParser(QUIET=True)\n",
    "    \n",
    "    heptad_positions = defaultdict(lambda: {'hydrophobic': 0, 'total': 0})\n",
    "    \n",
    "    with tqdm(total=len(pdb_files), desc=\"Hydrophobic patterns\") as pbar:\n",
    "        for pdb_file in pdb_files:\n",
    "            try:\n",
    "                structure = parser.get_structure(pdb_file.stem, str(pdb_file))\n",
    "                \n",
    "                for model in structure:\n",
    "                    for chain in model:\n",
    "                        residues = [r for r in chain if r.id[0] == ' ']\n",
    "                        \n",
    "                        for i, residue in enumerate(residues):\n",
    "                            pos_in_heptad = i % 7\n",
    "                            resname = residue.resname.strip()\n",
    "                            \n",
    "                            heptad_positions[pos_in_heptad]['total'] += 1\n",
    "                            if resname in hydrophobic:\n",
    "                                heptad_positions[pos_in_heptad]['hydrophobic'] += 1\n",
    "            \n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    return dict(heptad_positions)\n",
    "\n",
    "def analyze_aa_properties_distribution(all_residues: Counter) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analisa distribuição por propriedades físico-químicas\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    total = sum(all_residues.values())\n",
    "    \n",
    "    for property_name, aa_list in AA_PROPERTIES.items():\n",
    "        count = sum(all_residues.get(aa, 0) for aa in aa_list)\n",
    "        freq = (count / total * 100) if total > 0 else 0\n",
    "        \n",
    "        data.append({\n",
    "            'Property': property_name,\n",
    "            'Count': count,\n",
    "            'Frequency': freq\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def plot_helix_propensities(df: pd.DataFrame, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Gráfico de propensões de hélices\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    x = np.arange(len(df))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[0].bar(x - width/2, df['Propensity_Observed'], width,\n",
    "                label='Propensão Observada', color='steelblue', edgecolor='black')\n",
    "    axes[0].bar(x + width/2, df['Propensity_Theoretical'], width,\n",
    "                label='Propensão Teórica (Chou-Fasman)', color='coral', edgecolor='black')\n",
    "    axes[0].axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Propensão neutra')\n",
    "    axes[0].set_xlabel('Aminoácido')\n",
    "    axes[0].set_ylabel('Propensão para Hélice')\n",
    "    axes[0].set_title('Propensão de Aminoácidos para Hélices Alpha')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(df['AA'], rotation=0)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    axes[1].scatter(df['Freq_Total'], df['Freq_Helix'], s=100, alpha=0.6, color='steelblue')\n",
    "    for idx, row in df.iterrows():\n",
    "        axes[1].annotate(row['AA'], (row['Freq_Total'], row['Freq_Helix']),\n",
    "                        fontsize=9, ha='center')\n",
    "    \n",
    "    max_val = max(df['Freq_Total'].max(), df['Freq_Helix'].max())\n",
    "    axes[1].plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Frequência igual')\n",
    "    \n",
    "    axes[1].set_xlabel('Frequência Total (%)')\n",
    "    axes[1].set_ylabel('Frequência em Hélices (%)')\n",
    "    axes[1].set_title('Frequência de Aminoácidos: Total vs Hélices')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_file = analysis_path / \"helix_propensities.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_file}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_helix_positions(df: pd.DataFrame, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Heatmap de preferências por posição na hélice\n",
    "    \"\"\"\n",
    "    pivot = df.pivot(index='AA', columns='Position', values='Frequency')\n",
    "    pivot = pivot[['N-terminal', 'Middle', 'C-terminal']]\n",
    "    \n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.heatmap(pivot, annot=True, fmt='.1f', cmap='YlOrRd',\n",
    "                cbar_kws={'label': 'Frequência (%)'})\n",
    "    plt.title('Preferência de Aminoácidos por Posição na Hélice')\n",
    "    plt.ylabel('Aminoácido')\n",
    "    plt.xlabel('Posição')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_file = analysis_path / \"helix_positions.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_file}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_helix_length_distribution(helix_lengths: list, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Distribuição de comprimentos de hélices\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(helix_lengths, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Comprimento da Hélice (resíduos)')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.title('Distribuição de Comprimentos de Hélices')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(helix_lengths, vert=True)\n",
    "    plt.ylabel('Comprimento da Hélice (resíduos)')\n",
    "    plt.title('Box Plot - Comprimento de Hélices')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_file = analysis_path / \"helix_lengths.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_file}\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\nEstatísticas de comprimento de hélices:\")\n",
    "    print(f\"  Média: {np.mean(helix_lengths):.1f} resíduos\")\n",
    "    print(f\"  Mediana: {np.median(helix_lengths):.1f} resíduos\")\n",
    "    print(f\"  Desvio padrão: {np.std(helix_lengths):.1f}\")\n",
    "    print(f\"  Min: {min(helix_lengths)}, Max: {max(helix_lengths)}\")\n",
    "\n",
    "def plot_hydrophobic_heptad(heptad_data: dict, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Gráfico de padrão heptad\n",
    "    \"\"\"\n",
    "    positions = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n",
    "    hydrophobic_freq = []\n",
    "    \n",
    "    for i in range(7):\n",
    "        data = heptad_data[i]\n",
    "        freq = (data['hydrophobic'] / data['total'] * 100) if data['total'] > 0 else 0\n",
    "        hydrophobic_freq.append(freq)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(positions, hydrophobic_freq, color='steelblue', edgecolor='black')\n",
    "    plt.axhline(y=np.mean(hydrophobic_freq), color='red', linestyle='--',\n",
    "                alpha=0.5, label=f'Média: {np.mean(hydrophobic_freq):.1f}%')\n",
    "    plt.xlabel('Posição no Heptad Repeat')\n",
    "    plt.ylabel('Frequência de Aminoácidos Hidrofóbicos (%)')\n",
    "    plt.title('Padrão Heptad: Distribuição de Resíduos Hidrofóbicos')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_file = analysis_path / \"heptad_pattern.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_file}\")\n",
    "    plt.close()\n",
    "\n",
    "def save_comprehensive_report(analysis_path: Path, propensity_df: pd.DataFrame,\n",
    "                              position_df: pd.DataFrame, properties_df: pd.DataFrame,\n",
    "                              helix_lengths: list):\n",
    "    \"\"\"\n",
    "    Salva relatório abrangente\n",
    "    \"\"\"\n",
    "    report_file = analysis_path / \"helix_analysis_comprehensive_report.txt\"\n",
    "    \n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"ANÁLISE ABRANGENTE DE COMPOSIÇÃO DE HÉLICES ALPHA\\n\")\n",
    "        f.write(\"Estruturas CATH Mainly-Alpha\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"### PROPENSÃO DE AMINOÁCIDOS PARA HÉLICES ###\\n\\n\")\n",
    "        f.write(f\"{'AA':<5} {'Helix':<10} {'Total':<10} {'Prop.Obs':<12} {'Prop.Teor':<12}\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        for _, row in propensity_df.iterrows():\n",
    "            f.write(f\"{row['AA']:<5} {row['Count_Helix']:<10} {row['Count_Total']:<10} \"\n",
    "                   f\"{row['Propensity_Observed']:<12.2f} {row['Propensity_Theoretical']:<12.2f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n### TOP 5 FORMADORES DE HÉLICES (Propensão Observada) ###\\n\")\n",
    "        top_formers = propensity_df.nlargest(5, 'Propensity_Observed')\n",
    "        for idx, row in top_formers.iterrows():\n",
    "            f.write(f\"  {idx+1}. {row['AA']}: {row['Propensity_Observed']:.2f}\\n\")\n",
    "        \n",
    "        f.write(\"\\n### DISTRIBUIÇÃO POR PROPRIEDADES ###\\n\\n\")\n",
    "        for _, row in properties_df.iterrows():\n",
    "            f.write(f\"{row['Property']:<25}: {row['Frequency']:>6.2f}% ({row['Count']:,})\\n\")\n",
    "        \n",
    "        f.write(\"\\n### ESTATÍSTICAS DE COMPRIMENTO DE HÉLICES ###\\n\\n\")\n",
    "        f.write(f\"  Número total de hélices: {len(helix_lengths):,}\\n\")\n",
    "        f.write(f\"  Comprimento médio: {np.mean(helix_lengths):.1f} resíduos\\n\")\n",
    "        f.write(f\"  Mediana: {np.median(helix_lengths):.1f} resíduos\\n\")\n",
    "        f.write(f\"  Desvio padrão: {np.std(helix_lengths):.1f}\\n\")\n",
    "        f.write(f\"  Intervalo: {min(helix_lengths)} - {max(helix_lengths)} resíduos\\n\")\n",
    "        \n",
    "        percentiles = [25, 50, 75, 90, 95]\n",
    "        f.write(\"\\n  Percentis:\\n\")\n",
    "        for p in percentiles:\n",
    "            val = np.percentile(helix_lengths, p)\n",
    "            f.write(f\"    {p}%: {val:.1f} resíduos\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(f\"\\nRelatório abrangente salvo em: {report_file}\")\n",
    "    \n",
    "    propensity_df.to_csv(analysis_path / \"helix_propensities.csv\", index=False)\n",
    "    position_df.to_csv(analysis_path / \"helix_positions.csv\", index=False)\n",
    "    properties_df.to_csv(analysis_path / \"aa_properties_distribution.csv\", index=False)\n",
    "    \n",
    "    print(\"Arquivos CSV salvos:\")\n",
    "    print(\"  - helix_propensities.csv\")\n",
    "    print(\"  - helix_positions.csv\")\n",
    "    print(\"  - aa_properties_distribution.csv\")\n",
    "\n",
    "def run_helix_analysis():\n",
    "    \"\"\"\n",
    "    Executa todas as análises de hélices\n",
    "    \"\"\"\n",
    "    clean_dir = Path(CLEAN_STRUCTURES_PATH)\n",
    "    analysis_path = Path(BASE_PATH) / \"analysis\"\n",
    "    analysis_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ANÁLISE AVANÇADA DE HÉLICES ALPHA\")\n",
    "    print(\"Ambiente Local - Processamento Paralelo\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Análise com DSSP\n",
    "    dssp_results = analyze_secondary_structure_with_dssp(clean_dir, analysis_path)\n",
    "    \n",
    "    if dssp_results is None:\n",
    "        return\n",
    "    \n",
    "    # 2. Calcula propensões\n",
    "    propensity_df = calculate_helix_propensities(\n",
    "        dssp_results['helix_residues'],\n",
    "        dssp_results['all_residues']\n",
    "    )\n",
    "    \n",
    "    # 3. Analisa posições\n",
    "    position_df = analyze_helix_positions(dssp_results['helix_positions'])\n",
    "    \n",
    "    # 4. Analisa propriedades\n",
    "    properties_df = analyze_aa_properties_distribution(dssp_results['all_residues'])\n",
    "    \n",
    "    # 5. Analisa padrões hidrofóbicos\n",
    "    heptad_data = analyze_hydrophobic_patterns(clean_dir)\n",
    "    \n",
    "    # 6. Gera gráficos\n",
    "    print(\"\\nGerando visualizações...\")\n",
    "    plot_helix_propensities(propensity_df, analysis_path)\n",
    "    plot_helix_positions(position_df, analysis_path)\n",
    "    plot_helix_length_distribution(dssp_results['helix_lengths'], analysis_path)\n",
    "    plot_hydrophobic_heptad(heptad_data, analysis_path)\n",
    "    \n",
    "    # 7. Salva relatórios\n",
    "    save_comprehensive_report(\n",
    "        analysis_path,\n",
    "        propensity_df,\n",
    "        position_df,\n",
    "        properties_df,\n",
    "        dssp_results['helix_lengths']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISE CONCLUÍDA\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Executar análise\n",
    "if __name__ == \"__main__\":\n",
    "    run_helix_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zt9VcnuRNa2K"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Análise de tipos de hélices e composição específica por tipo\n",
    "Ambiente local com processamento paralelo\n",
    "\"\"\"\n",
    "\n",
    "from Bio import PDB\n",
    "from Bio.PDB import DSSP\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import multiprocessing\n",
    "\n",
    "# Configurações para ambiente local\n",
    "BASE_PATH = \"/Volumes/promethion/cath-mainly-alpha\"\n",
    "CLEAN_STRUCTURES_PATH = f\"{BASE_PATH}/structures_clean\"\n",
    "MAX_WORKERS = max(1, multiprocessing.cpu_count() - 1)\n",
    "\n",
    "# Definição de tipos de hélices (DSSP)\n",
    "HELIX_TYPES = {\n",
    "    'H': 'Alpha helix',\n",
    "    'G': '3-10 helix',\n",
    "    'I': 'Pi helix'\n",
    "}\n",
    "\n",
    "# Características estruturais dos tipos de hélices\n",
    "HELIX_CHARACTERISTICS = {\n",
    "    'H': {\n",
    "        'name': 'Alpha helix',\n",
    "        'residues_per_turn': 3.6,\n",
    "        'rise_per_residue': 1.5,\n",
    "        'hydrogen_bond': 'i to i+4',\n",
    "        'typical_length': '10-20 residues'\n",
    "    },\n",
    "    'G': {\n",
    "        'name': '3-10 helix',\n",
    "        'residues_per_turn': 3.0,\n",
    "        'rise_per_residue': 2.0,\n",
    "        'hydrogen_bond': 'i to i+3',\n",
    "        'typical_length': '3-5 residues'\n",
    "    },\n",
    "    'I': {\n",
    "        'name': 'Pi helix',\n",
    "        'residues_per_turn': 4.4,\n",
    "        'rise_per_residue': 1.15,\n",
    "        'hydrogen_bond': 'i to i+5',\n",
    "        'typical_length': '7-10 residues'\n",
    "    }\n",
    "}\n",
    "\n",
    "STANDARD_AMINO_ACIDS = {\n",
    "    'ALA', 'ARG', 'ASN', 'ASP', 'CYS',\n",
    "    'GLN', 'GLU', 'GLY', 'HIS', 'ILE',\n",
    "    'LEU', 'LYS', 'MET', 'PHE', 'PRO',\n",
    "    'SER', 'THR', 'TRP', 'TYR', 'VAL'\n",
    "}\n",
    "\n",
    "def classify_helix_types(clean_dir: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Classifica e analisa diferentes tipos de hélices\n",
    "    \"\"\"\n",
    "    print(\"\\nClassificando tipos de hélices com DSSP...\")\n",
    "    \n",
    "    pdb_files = list(clean_dir.glob(\"*.pdb\"))\n",
    "    parser = PDB.PDBParser(QUIET=True)\n",
    "    \n",
    "    helix_type_counts = Counter()\n",
    "    helix_type_residues = defaultdict(Counter)\n",
    "    helix_type_lengths = defaultdict(list)\n",
    "    helix_type_positions = defaultdict(lambda: defaultdict(Counter))\n",
    "    transitions = defaultdict(Counter)\n",
    "    \n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    structures_with_helices = defaultdict(int)\n",
    "    \n",
    "    with tqdm(total=len(pdb_files), desc=\"Classifying helix types\") as pbar:\n",
    "        for pdb_file in pdb_files:\n",
    "            pdb_code = pdb_file.stem\n",
    "            \n",
    "            try:\n",
    "                structure = parser.get_structure(pdb_code, str(pdb_file))\n",
    "                model = structure[0]\n",
    "                \n",
    "                dssp = DSSP(model, str(pdb_file), dssp='mkdssp')\n",
    "                \n",
    "                ss_sequence = []\n",
    "                aa_sequence = []\n",
    "                \n",
    "                for key in dssp.property_keys:\n",
    "                    residue = dssp[key]\n",
    "                    aa = residue[1]\n",
    "                    ss = residue[2]\n",
    "                    \n",
    "                    ss_sequence.append(ss)\n",
    "                    aa_sequence.append(aa)\n",
    "                \n",
    "                current_helix = {'type': None, 'residues': [], 'start': 0}\n",
    "                \n",
    "                for i, (ss, aa) in enumerate(zip(ss_sequence, aa_sequence)):\n",
    "                    if ss in ['H', 'G', 'I']:\n",
    "                        if current_helix['type'] == ss:\n",
    "                            current_helix['residues'].append(aa)\n",
    "                        else:\n",
    "                            if current_helix['type'] and len(current_helix['residues']) >= 3:\n",
    "                                helix_type = current_helix['type']\n",
    "                                residues = current_helix['residues']\n",
    "                                \n",
    "                                helix_type_counts[helix_type] += 1\n",
    "                                helix_type_lengths[helix_type].append(len(residues))\n",
    "                                structures_with_helices[helix_type] += 1\n",
    "                                \n",
    "                                for j, res in enumerate(residues):\n",
    "                                    helix_type_residues[helix_type][res] += 1\n",
    "                                    \n",
    "                                    if j == 0:\n",
    "                                        helix_type_positions[helix_type]['N-terminal'][res] += 1\n",
    "                                    elif j == len(residues) - 1:\n",
    "                                        helix_type_positions[helix_type]['C-terminal'][res] += 1\n",
    "                                    else:\n",
    "                                        helix_type_positions[helix_type]['Middle'][res] += 1\n",
    "                            \n",
    "                            if current_helix['type'] and current_helix['type'] != ss:\n",
    "                                transitions[current_helix['type']][ss] += 1\n",
    "                            \n",
    "                            current_helix = {'type': ss, 'residues': [aa], 'start': i}\n",
    "                    else:\n",
    "                        if current_helix['type'] and len(current_helix['residues']) >= 3:\n",
    "                            helix_type = current_helix['type']\n",
    "                            residues = current_helix['residues']\n",
    "                            \n",
    "                            helix_type_counts[helix_type] += 1\n",
    "                            helix_type_lengths[helix_type].append(len(residues))\n",
    "                            \n",
    "                            for j, res in enumerate(residues):\n",
    "                                helix_type_residues[helix_type][res] += 1\n",
    "                                \n",
    "                                if j == 0:\n",
    "                                    helix_type_positions[helix_type]['N-terminal'][res] += 1\n",
    "                                elif j == len(residues) - 1:\n",
    "                                    helix_type_positions[helix_type]['C-terminal'][res] += 1\n",
    "                                else:\n",
    "                                    helix_type_positions[helix_type]['Middle'][res] += 1\n",
    "                        \n",
    "                        current_helix = {'type': None, 'residues': [], 'start': 0}\n",
    "                \n",
    "                if current_helix['type'] and len(current_helix['residues']) >= 3:\n",
    "                    helix_type = current_helix['type']\n",
    "                    residues = current_helix['residues']\n",
    "                    \n",
    "                    helix_type_counts[helix_type] += 1\n",
    "                    helix_type_lengths[helix_type].append(len(residues))\n",
    "                    \n",
    "                    for j, res in enumerate(residues):\n",
    "                        helix_type_residues[helix_type][res] += 1\n",
    "                        \n",
    "                        if j == 0:\n",
    "                            helix_type_positions[helix_type]['N-terminal'][res] += 1\n",
    "                        elif j == len(residues) - 1:\n",
    "                            helix_type_positions[helix_type]['C-terminal'][res] += 1\n",
    "                        else:\n",
    "                            helix_type_positions[helix_type]['Middle'][res] += 1\n",
    "                \n",
    "                successful += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                failed += 1\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(f\"\\nClassificação concluída: {successful} sucessos, {failed} falhas\")\n",
    "    \n",
    "    return {\n",
    "        'helix_counts': dict(helix_type_counts),\n",
    "        'helix_residues': dict(helix_type_residues),\n",
    "        'helix_lengths': dict(helix_type_lengths),\n",
    "        'helix_positions': dict(helix_type_positions),\n",
    "        'transitions': dict(transitions),\n",
    "        'structures_analyzed': successful\n",
    "    }\n",
    "\n",
    "def analyze_helix_type_composition(helix_residues: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analisa composição de aminoácidos por tipo de hélice\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for helix_type, residue_counts in helix_residues.items():\n",
    "        total = sum(residue_counts.values())\n",
    "        helix_name = HELIX_TYPES.get(helix_type, helix_type)\n",
    "        \n",
    "        for aa in sorted(STANDARD_AMINO_ACIDS):\n",
    "            count = residue_counts.get(aa, 0)\n",
    "            freq = (count / total * 100) if total > 0 else 0\n",
    "            \n",
    "            data.append({\n",
    "                'Helix_Type': helix_type,\n",
    "                'Helix_Name': helix_name,\n",
    "                'AA': aa,\n",
    "                'Count': count,\n",
    "                'Frequency': freq\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def compare_helix_types(helix_residues: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compara os aminoácidos mais frequentes entre tipos de hélices\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for helix_type, residue_counts in helix_residues.items():\n",
    "        total = sum(residue_counts.values())\n",
    "        helix_name = HELIX_TYPES.get(helix_type, helix_type)\n",
    "        \n",
    "        top_aa = residue_counts.most_common(10)\n",
    "        \n",
    "        for rank, (aa, count) in enumerate(top_aa, 1):\n",
    "            freq = (count / total * 100) if total > 0 else 0\n",
    "            \n",
    "            data.append({\n",
    "                'Helix_Type': helix_type,\n",
    "                'Helix_Name': helix_name,\n",
    "                'Rank': rank,\n",
    "                'AA': aa,\n",
    "                'Count': count,\n",
    "                'Frequency': freq\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def statistical_comparison(composition_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Teste estatístico para diferenças significativas entre tipos\n",
    "    \"\"\"\n",
    "    helix_types = composition_df['Helix_Type'].unique()\n",
    "    \n",
    "    if len(helix_types) < 2:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for aa in sorted(STANDARD_AMINO_ACIDS):\n",
    "        aa_data = composition_df[composition_df['AA'] == aa]\n",
    "        \n",
    "        if 'H' in helix_types and 'G' in helix_types:\n",
    "            alpha_freq = aa_data[aa_data['Helix_Type'] == 'H']['Frequency'].values\n",
    "            g310_freq = aa_data[aa_data['Helix_Type'] == 'G']['Frequency'].values\n",
    "            \n",
    "            if len(alpha_freq) > 0 and len(g310_freq) > 0:\n",
    "                diff = alpha_freq[0] - g310_freq[0]\n",
    "                \n",
    "                results.append({\n",
    "                    'AA': aa,\n",
    "                    'Alpha_Freq': alpha_freq[0],\n",
    "                    '3-10_Freq': g310_freq[0],\n",
    "                    'Difference': diff,\n",
    "                    'Enriched_In': 'Alpha' if diff > 0 else '3-10'\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.sort_values('Difference', ascending=False, key=abs)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plot_helix_type_distribution(helix_counts: dict, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Gráfico de distribuição de tipos de hélices\n",
    "    \"\"\"\n",
    "    types = []\n",
    "    counts = []\n",
    "    names = []\n",
    "    \n",
    "    for helix_type in ['H', 'G', 'I']:\n",
    "        if helix_type in helix_counts:\n",
    "            types.append(helix_type)\n",
    "            counts.append(helix_counts[helix_type])\n",
    "            names.append(HELIX_TYPES[helix_type])\n",
    "    \n",
    "    total = sum(counts)\n",
    "    percentages = [(c/total*100) for c in counts]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    colors = ['steelblue', 'coral', 'lightgreen']\n",
    "    axes[0].bar(names, counts, color=colors[:len(names)], edgecolor='black')\n",
    "    axes[0].set_ylabel('Número de Hélices')\n",
    "    axes[0].set_title('Distribuição de Tipos de Hélices')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, (name, count, pct) in enumerate(zip(names, counts, percentages)):\n",
    "        axes[0].text(i, count, f'{count:,}\\n({pct:.1f}%)',\n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    axes[1].pie(counts, labels=names, autopct='%1.1f%%', colors=colors[:len(names)],\n",
    "                startangle=90, wedgeprops={'edgecolor': 'black'})\n",
    "    axes[1].set_title('Proporção de Tipos de Hélices')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_file = analysis_path / \"helix_type_distribution.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_file}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_helix_type_composition(composition_df: pd.DataFrame, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Heatmap comparativo de composição por tipo de hélice\n",
    "    \"\"\"\n",
    "    pivot = composition_df.pivot(index='AA', columns='Helix_Name', values='Frequency')\n",
    "    \n",
    "    if 'Alpha helix' in pivot.columns:\n",
    "        pivot = pivot.sort_values('Alpha helix', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 12))\n",
    "    sns.heatmap(pivot, annot=True, fmt='.1f', cmap='YlOrRd',\n",
    "                cbar_kws={'label': 'Frequência (%)'}, linewidths=0.5)\n",
    "    plt.title('Composição de Aminoácidos por Tipo de Hélice', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Aminoácido', fontsize=12)\n",
    "    plt.xlabel('Tipo de Hélice', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_file = analysis_path / \"helix_type_composition_heatmap.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_file}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_top_amino_acids_by_type(comparison_df: pd.DataFrame, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Gráfico dos aminoácidos mais frequentes por tipo\n",
    "    \"\"\"\n",
    "    helix_types = comparison_df['Helix_Name'].unique()\n",
    "    n_types = len(helix_types)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_types, figsize=(6*n_types, 6))\n",
    "    \n",
    "    if n_types == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    colors = ['steelblue', 'coral', 'lightgreen']\n",
    "    \n",
    "    for idx, helix_name in enumerate(helix_types):\n",
    "        data = comparison_df[comparison_df['Helix_Name'] == helix_name]\n",
    "        top10 = data.nsmallest(10, 'Rank')\n",
    "        \n",
    "        axes[idx].barh(top10['AA'], top10['Frequency'], color=colors[idx], edgecolor='black')\n",
    "        axes[idx].set_xlabel('Frequência (%)')\n",
    "        axes[idx].set_title(f'{helix_name}\\nTop 10 Aminoácidos', fontweight='bold')\n",
    "        axes[idx].invert_yaxis()\n",
    "        axes[idx].grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        for i, (aa, freq) in enumerate(zip(top10['AA'], top10['Frequency'])):\n",
    "            axes[idx].text(freq, i, f' {freq:.1f}%', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_file = analysis_path / \"helix_type_top_amino_acids.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_file}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_helix_length_comparison(helix_lengths: dict, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Comparação de distribuição de comprimentos por tipo\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    types_to_plot = [t for t in ['H', 'G', 'I'] if t in helix_lengths]\n",
    "    colors = ['steelblue', 'coral', 'lightgreen']\n",
    "    \n",
    "    data_to_plot = [helix_lengths[t] for t in types_to_plot]\n",
    "    labels = [HELIX_TYPES[t] for t in types_to_plot]\n",
    "    \n",
    "    bp = axes[0].boxplot(data_to_plot, labels=labels, patch_artist=True)\n",
    "    for patch, color in zip(bp['boxes'], colors[:len(types_to_plot)]):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    axes[0].set_ylabel('Comprimento (resíduos)')\n",
    "    axes[0].set_title('Distribuição de Comprimentos por Tipo de Hélice')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for helix_type, color in zip(types_to_plot, colors[:len(types_to_plot)]):\n",
    "        lengths = helix_lengths[helix_type]\n",
    "        axes[1].hist(lengths, bins=30, alpha=0.5, label=HELIX_TYPES[helix_type],\n",
    "                    color=color, edgecolor='black')\n",
    "    \n",
    "    axes[1].set_xlabel('Comprimento (resíduos)')\n",
    "    axes[1].set_ylabel('Frequência')\n",
    "    axes[1].set_title('Histograma de Comprimentos')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_file = analysis_path / \"helix_length_by_type.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_file}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_statistical_differences(stat_df: pd.DataFrame, analysis_path: Path):\n",
    "    \"\"\"\n",
    "    Gráfico de diferenças estatísticas entre Alpha e 3-10\n",
    "    \"\"\"\n",
    "    if stat_df.empty:\n",
    "        return\n",
    "    \n",
    "    top_diff = stat_df.head(10)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    colors = ['steelblue' if x > 0 else 'coral' for x in top_diff['Difference']]\n",
    "    axes[0].barh(top_diff['AA'], top_diff['Difference'], color=colors, edgecolor='black')\n",
    "    axes[0].axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    axes[0].set_xlabel('Diferença de Frequência (%)')\n",
    "    axes[0].set_title('Diferenças Mais Significativas:\\nAlpha helix vs 3-10 helix', fontweight='bold')\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='steelblue', label='Enriquecido em Alpha'),\n",
    "        Patch(facecolor='coral', label='Enriquecido em 3-10')\n",
    "    ]\n",
    "    axes[0].legend(handles=legend_elements)\n",
    "    \n",
    "    axes[1].scatter(top_diff['Alpha_Freq'], top_diff['3-10_Freq'],\n",
    "                   s=200, alpha=0.6, c=colors, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    for _, row in top_diff.iterrows():\n",
    "        axes[1].annotate(row['AA'],\n",
    "                        (row['Alpha_Freq'], row['3-10_Freq']),\n",
    "                        fontsize=10, ha='center', fontweight='bold')\n",
    "    \n",
    "    max_val = max(top_diff['Alpha_Freq'].max(), top_diff['3-10_Freq'].max())\n",
    "    axes[1].plot([0, max_val], [0, max_val], 'k--', alpha=0.3, label='Frequência igual')\n",
    "    \n",
    "    axes[1].set_xlabel('Frequência em Alpha helix (%)')\n",
    "    axes[1].set_ylabel('Frequência em 3-10 helix (%)')\n",
    "    axes[1].set_title('Comparação Direta: Alpha vs 3-10', fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_file = analysis_path / \"helix_type_statistical_comparison.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Gráfico salvo em: {plot_file}\")\n",
    "    plt.close()\n",
    "\n",
    "def save_helix_type_report(analysis_path: Path, results: dict,\n",
    "                           composition_df: pd.DataFrame, comparison_df: pd.DataFrame,\n",
    "                           stat_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Salva relatório detalhado sobre tipos de hélices\n",
    "    \"\"\"\n",
    "    report_file = analysis_path / \"helix_types_comprehensive_report.txt\"\n",
    "    \n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"ANÁLISE DETALHADA DE TIPOS DE HÉLICES\\n\")\n",
    "        f.write(\"Estruturas CATH Mainly-Alpha\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Estruturas analisadas: {results['structures_analyzed']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"### DISTRIBUIÇÃO DE TIPOS DE HÉLICES ###\\n\\n\")\n",
    "        total_helices = sum(results['helix_counts'].values())\n",
    "        f.write(f\"{'Tipo':<20} {'Nome':<20} {'Contagem':<12} {'Percentual':<12}\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        \n",
    "        for helix_type in ['H', 'G', 'I']:\n",
    "            if helix_type in results['helix_counts']:\n",
    "                count = results['helix_counts'][helix_type]\n",
    "                pct = (count / total_helices * 100) if total_helices > 0 else 0\n",
    "                name = HELIX_TYPES[helix_type]\n",
    "                f.write(f\"{helix_type:<20} {name:<20} {count:<12,} {pct:>10.1f}%\\n\")\n",
    "        \n",
    "        f.write(\"\\n### CARACTERÍSTICAS ESTRUTURAIS ###\\n\\n\")\n",
    "        for helix_type in ['H', 'G', 'I']:\n",
    "            if helix_type in results['helix_counts']:\n",
    "                char = HELIX_CHARACTERISTICS[helix_type]\n",
    "                f.write(f\"{char['name']}:\\n\")\n",
    "                f.write(f\"  Resíduos por volta: {char['residues_per_turn']}\\n\")\n",
    "                f.write(f\"  Aumento por resíduo: {char['rise_per_residue']} Å\\n\")\n",
    "                f.write(f\"  Ligação de hidrogênio: {char['hydrogen_bond']}\\n\")\n",
    "                f.write(f\"  Comprimento típico: {char['typical_length']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"### ESTATÍSTICAS DE COMPRIMENTO ###\\n\\n\")\n",
    "        for helix_type in ['H', 'G', 'I']:\n",
    "            if helix_type in results['helix_lengths']:\n",
    "                lengths = results['helix_lengths'][helix_type]\n",
    "                f.write(f\"{HELIX_TYPES[helix_type]}:\\n\")\n",
    "                f.write(f\"  Média: {np.mean(lengths):.1f} resíduos\\n\")\n",
    "                f.write(f\"  Mediana: {np.median(lengths):.1f} resíduos\\n\")\n",
    "                f.write(f\"  Desvio padrão: {np.std(lengths):.1f}\\n\")\n",
    "                f.write(f\"  Min-Max: {min(lengths)} - {max(lengths)} resíduos\\n\\n\")\n",
    "        \n",
    "        f.write(\"### TOP 5 AMINOÁCIDOS POR TIPO DE HÉLICE ###\\n\\n\")\n",
    "        for helix_type in ['H', 'G', 'I']:\n",
    "            if helix_type in results['helix_residues']:\n",
    "                f.write(f\"{HELIX_TYPES[helix_type]}:\\n\")\n",
    "                residues = results['helix_residues'][helix_type]\n",
    "                total = sum(residues.values())\n",
    "                \n",
    "                for rank, (aa, count) in enumerate(residues.most_common(5), 1):\n",
    "                    freq = (count / total * 100) if total > 0 else 0\n",
    "                    f.write(f\"  {rank}. {aa}: {freq:.2f}% ({count:,} resíduos)\\n\")\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        if not stat_df.empty:\n",
    "            f.write(\"### DIFERENÇAS SIGNIFICATIVAS (Alpha vs 3-10) ###\\n\\n\")\n",
    "            f.write(\"Top 10 aminoácidos com maiores diferenças:\\n\\n\")\n",
    "            f.write(f\"{'AA':<5} {'Alpha (%)':<12} {'3-10 (%)':<12} {'Diferença':<12} {'Enriquecido':<15}\\n\")\n",
    "            f.write(\"-\"*80 + \"\\n\")\n",
    "            \n",
    "            for _, row in stat_df.head(10).iterrows():\n",
    "                f.write(f\"{row['AA']:<5} {row['Alpha_Freq']:<12.2f} \"\n",
    "                       f\"{row['3-10_Freq']:<12.2f} {row['Difference']:<12.2f} \"\n",
    "                       f\"{row['Enriched_In']:<15}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(f\"\\nRelatório completo salvo em: {report_file}\")\n",
    "    \n",
    "    composition_df.to_csv(analysis_path / \"helix_type_composition.csv\", index=False)\n",
    "    comparison_df.to_csv(analysis_path / \"helix_type_top_residues.csv\", index=False)\n",
    "    \n",
    "    if not stat_df.empty:\n",
    "        stat_df.to_csv(analysis_path / \"helix_type_statistical_comparison.csv\", index=False)\n",
    "    \n",
    "    print(\"Arquivos CSV salvos:\")\n",
    "    print(\"  - helix_type_composition.csv\")\n",
    "    print(\"  - helix_type_top_residues.csv\")\n",
    "    print(\"  - helix_type_statistical_comparison.csv\")\n",
    "\n",
    "def run_helix_type_analysis():\n",
    "    \"\"\"\n",
    "    Executa análise completa de tipos de hélices\n",
    "    \"\"\"\n",
    "    clean_dir = Path(CLEAN_STRUCTURES_PATH)\n",
    "    analysis_path = Path(BASE_PATH) / \"analysis\"\n",
    "    analysis_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ANÁLISE DE TIPOS DE HÉLICES E COMPOSIÇÃO\")\n",
    "    print(\"Ambiente Local - Processamento Paralelo\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = classify_helix_types(clean_dir)\n",
    "    composition_df = analyze_helix_type_composition(results['helix_residues'])\n",
    "    comparison_df = compare_helix_types(results['helix_residues'])\n",
    "    stat_df = statistical_comparison(composition_df)\n",
    "    \n",
    "    print(\"\\nGerando visualizações...\")\n",
    "    plot_helix_type_distribution(results['helix_counts'], analysis_path)\n",
    "    plot_helix_type_composition(composition_df, analysis_path)\n",
    "    plot_top_amino_acids_by_type(comparison_df, analysis_path)\n",
    "    plot_helix_length_comparison(results['helix_lengths'], analysis_path)\n",
    "    \n",
    "    if not stat_df.empty:\n",
    "        plot_statistical_differences(stat_df, analysis_path)\n",
    "    \n",
    "    save_helix_type_report(analysis_path, results, composition_df, comparison_df, stat_df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESUMO DA ANÁLISE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for helix_type in ['H', 'G', 'I']:\n",
    "        if helix_type in results['helix_counts']:\n",
    "            count = results['helix_counts'][helix_type]\n",
    "            name = HELIX_TYPES[helix_type]\n",
    "            residues = results['helix_residues'][helix_type]\n",
    "            top_aa = residues.most_common(1)[0] if residues else ('N/A', 0)\n",
    "            \n",
    "            print(f\"\\n{name}:\")\n",
    "            print(f\"  Total: {count:,} hélices\")\n",
    "            print(f\"  Aminoácido mais frequente: {top_aa[0]} ({top_aa[1]:,} ocorrências)\")\n",
    "            \n",
    "            if helix_type in results['helix_lengths']:\n",
    "                lengths = results['helix_lengths'][helix_type]\n",
    "                print(f\"  Comprimento médio: {np.mean(lengths):.1f} resíduos\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISE CONCLUÍDA\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_helix_type_analysis()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0228f822aa624ac5987ecbd3bbe6cbf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1a4dd7776f748e4b348b0ed9928ce75",
      "placeholder": "​",
      "style": "IPY_MODEL_48dc0ee1b606403b8d95eef4d42f7415",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "0686afe9d4c741deb71ca3e6e401fbb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0d876f034b7c4c7fb5763f7eede217c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ee5fb2790ff4d78baa5ad19bdffad9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1480dfa86d9342df86a6b2dc9c4d91d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1854649ee670442791d36ace0e288eb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2641f2753d1a4e9da3f9bbab6f7f2685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92d2a2552fb741519a0f461ba756acf5",
       "IPY_MODEL_297baed59b124f63ad88025b11894011",
       "IPY_MODEL_8a202abdac1049a08387e2b20c85aab8"
      ],
      "layout": "IPY_MODEL_42f9116bd30c48c996a697ec3163f940"
     }
    },
    "279d2d92732048928c17e274786ca238": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7750d503440a43538b625fc684e88b0a",
      "placeholder": "​",
      "style": "IPY_MODEL_b80b6894f57c43c8a1e1a2734a53a62d",
      "value": "Downloading PDB structures: 100%"
     }
    },
    "293a22c8138243b78e986c8d1fe355a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "297baed59b124f63ad88025b11894011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d876f034b7c4c7fb5763f7eede217c5",
      "max": 50991,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1854649ee670442791d36ace0e288eb1",
      "value": 538
     }
    },
    "2a8ecdeae85c4edfba1d693a774fa5d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ff7a883eb9441609a2cfbc3186cfdb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35a27a27a4ec41e0963290252f54a74c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40411b06d28342339692ecddab06b64d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "419c7c9a4649464c80f32129dea17446": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbe9253cf1c24002bd57b8e724ac15ce",
       "IPY_MODEL_4632adc7b0f8403a84f67bd9d12f33cb",
       "IPY_MODEL_0228f822aa624ac5987ecbd3bbe6cbf7"
      ],
      "layout": "IPY_MODEL_293a22c8138243b78e986c8d1fe355a0"
     }
    },
    "42f9116bd30c48c996a697ec3163f940": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45b92ad879564fd79ca09b2941f5586c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c1f4f66b3f614e94b98c73abc81ffdcc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0a95389ac504fe38d51bcf762e1c602",
      "value": 0
     }
    },
    "4632adc7b0f8403a84f67bd9d12f33cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5535266ba4b42e89fe03b3dedf4b406",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0686afe9d4c741deb71ca3e6e401fbb3",
      "value": 0
     }
    },
    "48dc0ee1b606403b8d95eef4d42f7415": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e02ca279b324dea9e3f4d22d41cf9f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "693eea7c525c4a87a0e53a5a386c2523": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "724cf11fba894348b48d1185401726a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d620d548266542508af9faef614c9e87",
      "placeholder": "​",
      "style": "IPY_MODEL_5e02ca279b324dea9e3f4d22d41cf9f8",
      "value": "DSSP Analysis: "
     }
    },
    "7750d503440a43538b625fc684e88b0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a1596b23b184c2e89ca9a36039dcca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a202abdac1049a08387e2b20c85aab8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96d57df4024249398fb57774783dc437",
      "placeholder": "​",
      "style": "IPY_MODEL_2a8ecdeae85c4edfba1d693a774fa5d7",
      "value": " 538/50991 [00:09&lt;07:03, 119.00it/s, OK=0, Exist=529, NoChainA=9, Error=0]"
     }
    },
    "8d69b827e4fd420d8dcd3ef4c15d9357": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_279d2d92732048928c17e274786ca238",
       "IPY_MODEL_a1e81684459140fdbad74d6a1fc4ee6c",
       "IPY_MODEL_96b246706e324936a75ce111cbb332f0"
      ],
      "layout": "IPY_MODEL_b7be0571529745fdaedf886080fd0dff"
     }
    },
    "9036fc7677104d7c836ebdf9a4bc2db7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_724cf11fba894348b48d1185401726a8",
       "IPY_MODEL_45b92ad879564fd79ca09b2941f5586c",
       "IPY_MODEL_b3d7f88fa00c433e8f7e31f81b099100"
      ],
      "layout": "IPY_MODEL_ec7ce0b2be2c4c71bdfd0e99b213ac37"
     }
    },
    "92d2a2552fb741519a0f461ba756acf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc52aee002574e5b8914ec6666d173e2",
      "placeholder": "​",
      "style": "IPY_MODEL_7a1596b23b184c2e89ca9a36039dcca4",
      "value": "Cleaning structures:   1%"
     }
    },
    "96b246706e324936a75ce111cbb332f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ff7a883eb9441609a2cfbc3186cfdb6",
      "placeholder": "​",
      "style": "IPY_MODEL_1480dfa86d9342df86a6b2dc9c4d91d5",
      "value": " 50996/50996 [46:25&lt;00:00, 22.57it/s, Success=50991, Exists=0, Error=5]"
     }
    },
    "96d57df4024249398fb57774783dc437": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1e81684459140fdbad74d6a1fc4ee6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acffa65efda04945a511982dc9315528",
      "max": 50996,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_693eea7c525c4a87a0e53a5a386c2523",
      "value": 50996
     }
    },
    "acffa65efda04945a511982dc9315528": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3d7f88fa00c433e8f7e31f81b099100": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed02965954474837b16945d23df5bdd8",
      "placeholder": "​",
      "style": "IPY_MODEL_40411b06d28342339692ecddab06b64d",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "b7be0571529745fdaedf886080fd0dff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b80b6894f57c43c8a1e1a2734a53a62d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbe9253cf1c24002bd57b8e724ac15ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ee5fb2790ff4d78baa5ad19bdffad9a",
      "placeholder": "​",
      "style": "IPY_MODEL_35a27a27a4ec41e0963290252f54a74c",
      "value": "Hydrophobic patterns: "
     }
    },
    "c1f4f66b3f614e94b98c73abc81ffdcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "cc52aee002574e5b8914ec6666d173e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1a4dd7776f748e4b348b0ed9928ce75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5535266ba4b42e89fe03b3dedf4b406": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d620d548266542508af9faef614c9e87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0a95389ac504fe38d51bcf762e1c602": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ec7ce0b2be2c4c71bdfd0e99b213ac37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed02965954474837b16945d23df5bdd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
